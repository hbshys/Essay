部分数据由分布式服务器直接获取，如果后续数据量过大，可以只保留一条记录，使用MapReduce算法完成统计。

关于活跃度的：

1.推送的消息阅读量，大规模增长点的时间段，学院阅读分布、男女比例。
2.搜索附近人的时间段
3.聊天时间段
4.每日启动次数
5.分享消息的来源、类型。


关于学工的：
1.学生参与活动的分布
2.教职工活跃时间段

另外附里程碑如下，此里程碑仅做参考。

2月
数据挖掘框架文档编写（30页）
学工数据消密（模糊掉学号）导入HBase
提供Hive查询的文档（10页）

PS: 考虑多个学校横向的数据对比，有了Hive之后，每个人都可以交互式的检索数据仓库中的数据

3月
app数据导入HDFS
分词，提取停止词和特征词，按照每人每月的记录保存进HBase

PS：每个用户每个月的特征

4月
stream功能分析
实时分词，过滤停止词，可添加新的词
实时识别敏感词
热词分析

PS：大规模使用之后，随时监控聊天情况

5月

人员聚类

PS：根据2月、3月的工作，使用家庭地址、聊天特征词、分享墙数量等，对人员进行聚类，看哪些特性更能区分人

6月

用户活跃度

PS：需要五月的结果，看哪一类用户不用我们的产品或者离我们而去了，哪一类用户更活跃

7月

热点推荐

PS：哪些活动最受欢迎，不同特征的新闻更容易被哪些用户转发

8月

实时检索

PS：用户可以实时的检索自己已经发过的分享墙，也可以见过公共信息

9月

行为演进

PS：使用前几个月的数据，尤其是3月份开始的每月数据和五月份开始的聚类数据，看一个人的轨迹，对于类别变化的，需要格外的关注

10月

精准营销

PS：使用5月、9月的结果，并结合其它数据，建立A/B测试机制，检测精准营销的效果。

11月

爬虫

PS：爬取我们需要的一些政策、活动等，根据10月的结果进行推送

12月

用户消费行为分析

PS：10月的后续计划

1月

用户活跃度分析

PS：产品线基本完善，年底再来一次多维度的分析
